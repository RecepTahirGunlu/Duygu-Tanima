{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMS1pSWMCFOvI1kwU44Cyuu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import keras\n","from keras.models import Sequential, Model, model_from_json\n","from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\n","from keras.utils import np_utils\n","from keras.preprocessing import image\n","from keras.callbacks import ModelCheckpoint\n","import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt"],"metadata":{"id":"VwKYZC9NCpHq","executionInfo":{"status":"ok","timestamp":1685021340794,"user_tz":-180,"elapsed":5564,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9i1jG9h4ClCI","executionInfo":{"status":"ok","timestamp":1685021352323,"user_tz":-180,"elapsed":11547,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}}},"outputs":[],"source":["url = \"https://media.githubusercontent.com/media/RecepTahirGunlu/Duygu-Tanima/master/train.csv\"\n","train_data = pd.read_csv(url)"]},{"cell_type":"code","source":["train_pixels = train_data.pixel_values.str.split(\" \").tolist() \n","\n","train_pixels = pd.DataFrame(train_pixels, dtype=int)\n","train_images = train_pixels.values\n","train_images = train_images.astype(np.float)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWW89vOtCyza","executionInfo":{"status":"ok","timestamp":1685021415567,"user_tz":-180,"elapsed":63273,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"c587e3d0-3b09-4a71-9d1d-ab63b9a8db36"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-d19d62363e03>:3: FutureWarning: Could not cast to int64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n","  train_pixels = pd.DataFrame(train_pixels, dtype=int)\n","<ipython-input-3-d19d62363e03>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  train_images = train_images.astype(np.float)\n"]}]},{"cell_type":"code","source":["def show(img):\n","    show_image = img.reshape(48,48)\n","    \n","    plt.axis('off')\n","    plt.imshow(show_image, cmap='gray')\n","    \n","show(train_images[54])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"cm7IOATDC9HM","executionInfo":{"status":"ok","timestamp":1685021415568,"user_tz":-180,"elapsed":23,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"e03fbb95-8c78-4a7a-dd2e-0e234daa9efd"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["train_labels_flat = train_data[\"emotion\"].values.ravel()\n","train_labels_count = np.unique(train_labels_flat).shape[0]\n","\n","\n","def dense_to_one_hot(labels_dense, num_classes):\n","    num_labels = labels_dense.shape[0]\n","    index_offset = np.arange(num_labels) * num_classes\n","    labels_one_hot = np.zeros((num_labels, num_classes))\n","    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n","    return labels_one_hot\n","\n","y_train = dense_to_one_hot(train_labels_flat, train_labels_count)\n","\n","y_train = y_train.astype(np.uint8)\n","\n","print(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-WdwOdxDQej","executionInfo":{"status":"ok","timestamp":1685021415569,"user_tz":-180,"elapsed":20,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"0bfdaefe-7ad3-429c-e023-69465a887511"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 0 0 ... 0 0 0]\n"," [1 0 0 ... 0 0 0]\n"," [1 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]]\n"]}]},{"cell_type":"code","source":["url = \"https://media.githubusercontent.com/media/RecepTahirGunlu/Duygu-Tanima/master/validation.csv\"\n","test_data = pd.read_csv(url)\n","test_pixels = test_data.pixel_values.str.split(\" \").tolist() \n","\n","test_pixels = pd.DataFrame(test_pixels, dtype=int)\n","test_images = test_pixels.values\n","test_images = test_images.astype(np.float)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_KDrMv0D5Iz","executionInfo":{"status":"ok","timestamp":1685021427680,"user_tz":-180,"elapsed":12126,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"a2077ebb-1637-4013-ee3f-8f5a42203e7d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-151e24bdfde4>:5: FutureWarning: Could not cast to int64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n","  test_pixels = pd.DataFrame(test_pixels, dtype=int)\n","<ipython-input-6-151e24bdfde4>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  test_images = test_images.astype(np.float)\n"]}]},{"cell_type":"code","source":["test_labels_flat = test_data[\"emotion\"].values.ravel()\n","test_labels_count = np.unique(test_labels_flat).shape[0]\n","\n","y_test = dense_to_one_hot(test_labels_flat, test_labels_count)\n","\n","y_test = y_test.astype(np.uint8)"],"metadata":{"id":"JBDm0NxmFdFH","executionInfo":{"status":"ok","timestamp":1685021427681,"user_tz":-180,"elapsed":31,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x_train = train_images.reshape(-1, 48, 48, 1)\n","x_test = test_images.reshape(-1, 48, 48, 1)"],"metadata":{"id":"UfXopVWLEKYY","executionInfo":{"status":"ok","timestamp":1685021427682,"user_tz":-180,"elapsed":29,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","\n","# 1 . katman \n","\n","model.add(Conv2D(64, 3, data_format='channels_last', kernel_initializer=\"he_normal\", input_shape=(48,48,1)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","# yeni katman\n","#model.add(Conv2D(64, 3))\n","#model.add(BatchNormalization())\n","#model.add(Activation('relu'))\n","\n","# 2. katman\n","\n","model.add(Conv2D(64, 3))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=2))\n","model.add(Dropout(0.3))\n","\n","# 3. katman\n","\n","model.add(Conv2D(32,3))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","# 4. katman\n","\n","model.add(Conv2D(32,3))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","# 5. katman\n","\n","model.add(Conv2D(32, 3))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=2))\n","model.add(Dropout(0.3))\n","\n","# verktoilizasyon yapıyoruz\n","\n","model.add(Flatten())\n","model.add(Dense(128))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.3))\n","\n","# cikis katmani\n","\n","model.add(Dense(7))\n","model.add(Activation('softmax'))\n","\n","opt = keras.optimizers.RMSprop(learning_rate=.0001)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfPViKFxES1a","executionInfo":{"status":"ok","timestamp":1685028803670,"user_tz":-180,"elapsed":888,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"c01b758c-446e-4572-886e-35dd32bb5419"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_33 (Conv2D)          (None, 46, 46, 64)        640       \n","                                                                 \n"," batch_normalization_39 (Bat  (None, 46, 46, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," activation_45 (Activation)  (None, 46, 46, 64)        0         \n","                                                                 \n"," conv2d_34 (Conv2D)          (None, 44, 44, 64)        36928     \n","                                                                 \n"," batch_normalization_40 (Bat  (None, 44, 44, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," activation_46 (Activation)  (None, 44, 44, 64)        0         \n","                                                                 \n"," max_pooling2d_12 (MaxPoolin  (None, 22, 22, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_18 (Dropout)        (None, 22, 22, 64)        0         \n","                                                                 \n"," conv2d_35 (Conv2D)          (None, 20, 20, 32)        18464     \n","                                                                 \n"," batch_normalization_41 (Bat  (None, 20, 20, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," activation_47 (Activation)  (None, 20, 20, 32)        0         \n","                                                                 \n"," conv2d_36 (Conv2D)          (None, 18, 18, 32)        9248      \n","                                                                 \n"," batch_normalization_42 (Bat  (None, 18, 18, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," activation_48 (Activation)  (None, 18, 18, 32)        0         \n","                                                                 \n"," conv2d_37 (Conv2D)          (None, 16, 16, 32)        9248      \n","                                                                 \n"," batch_normalization_43 (Bat  (None, 16, 16, 32)       128       \n"," chNormalization)                                                \n","                                                                 \n"," activation_49 (Activation)  (None, 16, 16, 32)        0         \n","                                                                 \n"," max_pooling2d_13 (MaxPoolin  (None, 8, 8, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_19 (Dropout)        (None, 8, 8, 32)          0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 2048)              0         \n","                                                                 \n"," dense_12 (Dense)            (None, 128)               262272    \n","                                                                 \n"," batch_normalization_44 (Bat  (None, 128)              512       \n"," chNormalization)                                                \n","                                                                 \n"," activation_50 (Activation)  (None, 128)               0         \n","                                                                 \n"," dropout_20 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_13 (Dense)            (None, 7)                 903       \n","                                                                 \n"," activation_51 (Activation)  (None, 7)                 0         \n","                                                                 \n","=================================================================\n","Total params: 339,111\n","Trainable params: 338,407\n","Non-trainable params: 704\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["epochs = 50\n","batchSize = 100\n","\n","history = model.fit(x_train, y_train, \n","                    epochs=epochs, \n","                    shuffle=True,\n","                    batch_size=batchSize, \n","                    validation_data=(x_test, y_test), \n","                    verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKbcTOlpEVgU","executionInfo":{"status":"ok","timestamp":1685030098235,"user_tz":-180,"elapsed":1286343,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}},"outputId":"1f473258-b494-4a5d-8584-c0bf544b7cde"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","322/322 - 19s - loss: 1.6839 - accuracy: 0.3680 - val_loss: 1.6941 - val_accuracy: 0.3783 - 19s/epoch - 59ms/step\n","Epoch 2/100\n","322/322 - 12s - loss: 1.3210 - accuracy: 0.4977 - val_loss: 1.2175 - val_accuracy: 0.5341 - 12s/epoch - 38ms/step\n","Epoch 3/100\n","322/322 - 12s - loss: 1.2039 - accuracy: 0.5452 - val_loss: 1.2375 - val_accuracy: 0.5336 - 12s/epoch - 38ms/step\n","Epoch 4/100\n","322/322 - 12s - loss: 1.1342 - accuracy: 0.5716 - val_loss: 1.0854 - val_accuracy: 0.5858 - 12s/epoch - 38ms/step\n","Epoch 5/100\n","322/322 - 12s - loss: 1.0893 - accuracy: 0.5894 - val_loss: 1.1048 - val_accuracy: 0.5786 - 12s/epoch - 39ms/step\n","Epoch 6/100\n","322/322 - 12s - loss: 1.0550 - accuracy: 0.6004 - val_loss: 1.0998 - val_accuracy: 0.5782 - 12s/epoch - 39ms/step\n","Epoch 7/100\n","322/322 - 12s - loss: 1.0186 - accuracy: 0.6168 - val_loss: 1.0644 - val_accuracy: 0.5898 - 12s/epoch - 39ms/step\n","Epoch 8/100\n","322/322 - 12s - loss: 0.9924 - accuracy: 0.6229 - val_loss: 1.0950 - val_accuracy: 0.5900 - 12s/epoch - 38ms/step\n","Epoch 9/100\n","322/322 - 12s - loss: 0.9648 - accuracy: 0.6370 - val_loss: 1.0272 - val_accuracy: 0.6136 - 12s/epoch - 38ms/step\n","Epoch 10/100\n","322/322 - 12s - loss: 0.9417 - accuracy: 0.6428 - val_loss: 1.0178 - val_accuracy: 0.6183 - 12s/epoch - 39ms/step\n","Epoch 11/100\n","322/322 - 13s - loss: 0.9130 - accuracy: 0.6566 - val_loss: 1.0424 - val_accuracy: 0.6094 - 13s/epoch - 39ms/step\n","Epoch 12/100\n","322/322 - 13s - loss: 0.8983 - accuracy: 0.6609 - val_loss: 1.0015 - val_accuracy: 0.6265 - 13s/epoch - 39ms/step\n","Epoch 13/100\n","322/322 - 12s - loss: 0.8748 - accuracy: 0.6704 - val_loss: 1.0061 - val_accuracy: 0.6213 - 12s/epoch - 38ms/step\n","Epoch 14/100\n","322/322 - 12s - loss: 0.8612 - accuracy: 0.6779 - val_loss: 1.0128 - val_accuracy: 0.6237 - 12s/epoch - 38ms/step\n","Epoch 15/100\n","322/322 - 12s - loss: 0.8315 - accuracy: 0.6912 - val_loss: 1.0317 - val_accuracy: 0.6203 - 12s/epoch - 38ms/step\n","Epoch 16/100\n","322/322 - 13s - loss: 0.8207 - accuracy: 0.6914 - val_loss: 1.0142 - val_accuracy: 0.6255 - 13s/epoch - 39ms/step\n","Epoch 17/100\n","322/322 - 12s - loss: 0.8093 - accuracy: 0.6955 - val_loss: 1.0010 - val_accuracy: 0.6326 - 12s/epoch - 38ms/step\n","Epoch 18/100\n","322/322 - 13s - loss: 0.7862 - accuracy: 0.7047 - val_loss: 1.0044 - val_accuracy: 0.6331 - 13s/epoch - 39ms/step\n","Epoch 19/100\n","322/322 - 13s - loss: 0.7687 - accuracy: 0.7138 - val_loss: 0.9920 - val_accuracy: 0.6341 - 13s/epoch - 40ms/step\n","Epoch 20/100\n","322/322 - 12s - loss: 0.7592 - accuracy: 0.7137 - val_loss: 0.9912 - val_accuracy: 0.6418 - 12s/epoch - 39ms/step\n","Epoch 21/100\n","322/322 - 13s - loss: 0.7377 - accuracy: 0.7248 - val_loss: 1.0269 - val_accuracy: 0.6341 - 13s/epoch - 39ms/step\n","Epoch 22/100\n","322/322 - 13s - loss: 0.7242 - accuracy: 0.7288 - val_loss: 1.0217 - val_accuracy: 0.6408 - 13s/epoch - 39ms/step\n","Epoch 23/100\n","322/322 - 13s - loss: 0.7037 - accuracy: 0.7367 - val_loss: 0.9990 - val_accuracy: 0.6478 - 13s/epoch - 39ms/step\n","Epoch 24/100\n","322/322 - 12s - loss: 0.7009 - accuracy: 0.7378 - val_loss: 1.0468 - val_accuracy: 0.6242 - 12s/epoch - 39ms/step\n","Epoch 25/100\n","322/322 - 12s - loss: 0.6942 - accuracy: 0.7375 - val_loss: 1.0114 - val_accuracy: 0.6443 - 12s/epoch - 39ms/step\n","Epoch 26/100\n","322/322 - 12s - loss: 0.6778 - accuracy: 0.7476 - val_loss: 1.0117 - val_accuracy: 0.6440 - 12s/epoch - 39ms/step\n","Epoch 27/100\n","322/322 - 12s - loss: 0.6628 - accuracy: 0.7508 - val_loss: 1.0122 - val_accuracy: 0.6445 - 12s/epoch - 39ms/step\n","Epoch 28/100\n","322/322 - 12s - loss: 0.6557 - accuracy: 0.7533 - val_loss: 1.0083 - val_accuracy: 0.6507 - 12s/epoch - 39ms/step\n","Epoch 29/100\n","322/322 - 12s - loss: 0.6484 - accuracy: 0.7587 - val_loss: 0.9959 - val_accuracy: 0.6463 - 12s/epoch - 39ms/step\n","Epoch 30/100\n","322/322 - 13s - loss: 0.6370 - accuracy: 0.7598 - val_loss: 1.0181 - val_accuracy: 0.6473 - 13s/epoch - 39ms/step\n","Epoch 31/100\n","322/322 - 12s - loss: 0.6226 - accuracy: 0.7683 - val_loss: 1.0299 - val_accuracy: 0.6480 - 12s/epoch - 39ms/step\n","Epoch 32/100\n","322/322 - 13s - loss: 0.6156 - accuracy: 0.7691 - val_loss: 1.0452 - val_accuracy: 0.6468 - 13s/epoch - 39ms/step\n","Epoch 33/100\n","322/322 - 12s - loss: 0.6074 - accuracy: 0.7726 - val_loss: 1.0255 - val_accuracy: 0.6460 - 12s/epoch - 39ms/step\n","Epoch 34/100\n","322/322 - 12s - loss: 0.6000 - accuracy: 0.7731 - val_loss: 1.0179 - val_accuracy: 0.6510 - 12s/epoch - 38ms/step\n","Epoch 35/100\n","322/322 - 12s - loss: 0.5928 - accuracy: 0.7786 - val_loss: 1.0576 - val_accuracy: 0.6465 - 12s/epoch - 38ms/step\n","Epoch 36/100\n","322/322 - 12s - loss: 0.5863 - accuracy: 0.7808 - val_loss: 1.0813 - val_accuracy: 0.6396 - 12s/epoch - 38ms/step\n","Epoch 37/100\n","322/322 - 12s - loss: 0.5749 - accuracy: 0.7888 - val_loss: 1.0665 - val_accuracy: 0.6455 - 12s/epoch - 38ms/step\n","Epoch 38/100\n","322/322 - 13s - loss: 0.5719 - accuracy: 0.7849 - val_loss: 1.0658 - val_accuracy: 0.6426 - 13s/epoch - 39ms/step\n","Epoch 39/100\n","322/322 - 12s - loss: 0.5636 - accuracy: 0.7908 - val_loss: 1.0504 - val_accuracy: 0.6480 - 12s/epoch - 38ms/step\n","Epoch 40/100\n","322/322 - 13s - loss: 0.5608 - accuracy: 0.7922 - val_loss: 1.0744 - val_accuracy: 0.6463 - 13s/epoch - 39ms/step\n","Epoch 41/100\n","322/322 - 13s - loss: 0.5481 - accuracy: 0.7953 - val_loss: 1.0715 - val_accuracy: 0.6440 - 13s/epoch - 39ms/step\n","Epoch 42/100\n","322/322 - 12s - loss: 0.5479 - accuracy: 0.7945 - val_loss: 1.0790 - val_accuracy: 0.6386 - 12s/epoch - 38ms/step\n","Epoch 43/100\n","322/322 - 12s - loss: 0.5334 - accuracy: 0.8014 - val_loss: 1.0807 - val_accuracy: 0.6480 - 12s/epoch - 38ms/step\n","Epoch 44/100\n","322/322 - 13s - loss: 0.5373 - accuracy: 0.7995 - val_loss: 1.1079 - val_accuracy: 0.6309 - 13s/epoch - 39ms/step\n","Epoch 45/100\n","322/322 - 12s - loss: 0.5279 - accuracy: 0.8017 - val_loss: 1.1483 - val_accuracy: 0.6381 - 12s/epoch - 39ms/step\n","Epoch 46/100\n","322/322 - 13s - loss: 0.5287 - accuracy: 0.8036 - val_loss: 1.0683 - val_accuracy: 0.6435 - 13s/epoch - 40ms/step\n","Epoch 47/100\n","322/322 - 13s - loss: 0.5153 - accuracy: 0.8070 - val_loss: 1.0848 - val_accuracy: 0.6500 - 13s/epoch - 39ms/step\n","Epoch 48/100\n","322/322 - 12s - loss: 0.5092 - accuracy: 0.8087 - val_loss: 1.1172 - val_accuracy: 0.6440 - 12s/epoch - 38ms/step\n","Epoch 49/100\n","322/322 - 13s - loss: 0.5105 - accuracy: 0.8080 - val_loss: 1.0992 - val_accuracy: 0.6418 - 13s/epoch - 39ms/step\n","Epoch 50/100\n","322/322 - 12s - loss: 0.5039 - accuracy: 0.8142 - val_loss: 1.0633 - val_accuracy: 0.6497 - 12s/epoch - 38ms/step\n","Epoch 51/100\n","322/322 - 12s - loss: 0.4988 - accuracy: 0.8143 - val_loss: 1.1006 - val_accuracy: 0.6567 - 12s/epoch - 38ms/step\n","Epoch 52/100\n","322/322 - 13s - loss: 0.4956 - accuracy: 0.8168 - val_loss: 1.0956 - val_accuracy: 0.6443 - 13s/epoch - 39ms/step\n","Epoch 53/100\n","322/322 - 13s - loss: 0.4913 - accuracy: 0.8167 - val_loss: 1.1186 - val_accuracy: 0.6492 - 13s/epoch - 39ms/step\n","Epoch 54/100\n","322/322 - 12s - loss: 0.4904 - accuracy: 0.8190 - val_loss: 1.0945 - val_accuracy: 0.6502 - 12s/epoch - 38ms/step\n","Epoch 55/100\n","322/322 - 12s - loss: 0.4786 - accuracy: 0.8194 - val_loss: 1.1241 - val_accuracy: 0.6544 - 12s/epoch - 39ms/step\n","Epoch 56/100\n","322/322 - 13s - loss: 0.4874 - accuracy: 0.8184 - val_loss: 1.0981 - val_accuracy: 0.6497 - 13s/epoch - 39ms/step\n","Epoch 57/100\n","322/322 - 13s - loss: 0.4824 - accuracy: 0.8197 - val_loss: 1.1076 - val_accuracy: 0.6487 - 13s/epoch - 39ms/step\n","Epoch 58/100\n","322/322 - 12s - loss: 0.4795 - accuracy: 0.8223 - val_loss: 1.1373 - val_accuracy: 0.6532 - 12s/epoch - 38ms/step\n","Epoch 59/100\n","322/322 - 13s - loss: 0.4704 - accuracy: 0.8242 - val_loss: 1.1528 - val_accuracy: 0.6440 - 13s/epoch - 39ms/step\n","Epoch 60/100\n","322/322 - 13s - loss: 0.4660 - accuracy: 0.8269 - val_loss: 1.1256 - val_accuracy: 0.6507 - 13s/epoch - 39ms/step\n","Epoch 61/100\n","322/322 - 12s - loss: 0.4677 - accuracy: 0.8272 - val_loss: 1.1497 - val_accuracy: 0.6572 - 12s/epoch - 38ms/step\n","Epoch 62/100\n","322/322 - 12s - loss: 0.4570 - accuracy: 0.8304 - val_loss: 1.1348 - val_accuracy: 0.6522 - 12s/epoch - 38ms/step\n","Epoch 63/100\n","322/322 - 13s - loss: 0.4583 - accuracy: 0.8281 - val_loss: 1.1577 - val_accuracy: 0.6475 - 13s/epoch - 39ms/step\n","Epoch 64/100\n","322/322 - 13s - loss: 0.4547 - accuracy: 0.8328 - val_loss: 1.1339 - val_accuracy: 0.6527 - 13s/epoch - 39ms/step\n","Epoch 65/100\n","322/322 - 12s - loss: 0.4483 - accuracy: 0.8341 - val_loss: 1.1986 - val_accuracy: 0.6349 - 12s/epoch - 38ms/step\n","Epoch 66/100\n","322/322 - 12s - loss: 0.4518 - accuracy: 0.8329 - val_loss: 1.1390 - val_accuracy: 0.6490 - 12s/epoch - 39ms/step\n","Epoch 67/100\n","322/322 - 13s - loss: 0.4492 - accuracy: 0.8340 - val_loss: 1.1755 - val_accuracy: 0.6495 - 13s/epoch - 39ms/step\n","Epoch 68/100\n","322/322 - 12s - loss: 0.4496 - accuracy: 0.8307 - val_loss: 1.1569 - val_accuracy: 0.6458 - 12s/epoch - 39ms/step\n","Epoch 69/100\n","322/322 - 12s - loss: 0.4427 - accuracy: 0.8338 - val_loss: 1.1434 - val_accuracy: 0.6473 - 12s/epoch - 38ms/step\n","Epoch 70/100\n","322/322 - 12s - loss: 0.4436 - accuracy: 0.8335 - val_loss: 1.1258 - val_accuracy: 0.6480 - 12s/epoch - 38ms/step\n","Epoch 71/100\n","322/322 - 12s - loss: 0.4377 - accuracy: 0.8357 - val_loss: 1.1915 - val_accuracy: 0.6433 - 12s/epoch - 38ms/step\n","Epoch 72/100\n","322/322 - 12s - loss: 0.4333 - accuracy: 0.8379 - val_loss: 1.1330 - val_accuracy: 0.6515 - 12s/epoch - 38ms/step\n","Epoch 73/100\n","322/322 - 12s - loss: 0.4298 - accuracy: 0.8414 - val_loss: 1.1591 - val_accuracy: 0.6544 - 12s/epoch - 38ms/step\n","Epoch 74/100\n","322/322 - 13s - loss: 0.4308 - accuracy: 0.8405 - val_loss: 1.1337 - val_accuracy: 0.6495 - 13s/epoch - 39ms/step\n","Epoch 75/100\n","322/322 - 13s - loss: 0.4234 - accuracy: 0.8445 - val_loss: 1.1783 - val_accuracy: 0.6532 - 13s/epoch - 39ms/step\n","Epoch 76/100\n","322/322 - 12s - loss: 0.4305 - accuracy: 0.8414 - val_loss: 1.2067 - val_accuracy: 0.6440 - 12s/epoch - 38ms/step\n","Epoch 77/100\n","322/322 - 12s - loss: 0.4257 - accuracy: 0.8419 - val_loss: 1.1696 - val_accuracy: 0.6497 - 12s/epoch - 38ms/step\n","Epoch 78/100\n","322/322 - 12s - loss: 0.4237 - accuracy: 0.8436 - val_loss: 1.1946 - val_accuracy: 0.6554 - 12s/epoch - 38ms/step\n","Epoch 79/100\n","322/322 - 13s - loss: 0.4191 - accuracy: 0.8457 - val_loss: 1.1590 - val_accuracy: 0.6497 - 13s/epoch - 40ms/step\n","Epoch 80/100\n","322/322 - 13s - loss: 0.4158 - accuracy: 0.8461 - val_loss: 1.1595 - val_accuracy: 0.6468 - 13s/epoch - 39ms/step\n","Epoch 81/100\n","322/322 - 13s - loss: 0.4157 - accuracy: 0.8452 - val_loss: 1.1755 - val_accuracy: 0.6500 - 13s/epoch - 39ms/step\n","Epoch 82/100\n","322/322 - 12s - loss: 0.4208 - accuracy: 0.8415 - val_loss: 1.1450 - val_accuracy: 0.6458 - 12s/epoch - 38ms/step\n","Epoch 83/100\n","322/322 - 13s - loss: 0.4124 - accuracy: 0.8471 - val_loss: 1.1883 - val_accuracy: 0.6497 - 13s/epoch - 40ms/step\n","Epoch 84/100\n","322/322 - 12s - loss: 0.4087 - accuracy: 0.8475 - val_loss: 1.1784 - val_accuracy: 0.6547 - 12s/epoch - 38ms/step\n","Epoch 85/100\n","322/322 - 13s - loss: 0.4151 - accuracy: 0.8475 - val_loss: 1.1916 - val_accuracy: 0.6530 - 13s/epoch - 39ms/step\n","Epoch 86/100\n","322/322 - 12s - loss: 0.4060 - accuracy: 0.8522 - val_loss: 1.2302 - val_accuracy: 0.6413 - 12s/epoch - 38ms/step\n","Epoch 87/100\n","322/322 - 13s - loss: 0.4083 - accuracy: 0.8499 - val_loss: 1.1693 - val_accuracy: 0.6510 - 13s/epoch - 39ms/step\n","Epoch 88/100\n","322/322 - 12s - loss: 0.4020 - accuracy: 0.8515 - val_loss: 1.1991 - val_accuracy: 0.6520 - 12s/epoch - 39ms/step\n","Epoch 89/100\n","322/322 - 13s - loss: 0.3958 - accuracy: 0.8516 - val_loss: 1.2028 - val_accuracy: 0.6492 - 13s/epoch - 39ms/step\n","Epoch 90/100\n","322/322 - 13s - loss: 0.4038 - accuracy: 0.8499 - val_loss: 1.1988 - val_accuracy: 0.6495 - 13s/epoch - 40ms/step\n","Epoch 91/100\n","322/322 - 12s - loss: 0.4032 - accuracy: 0.8514 - val_loss: 1.2022 - val_accuracy: 0.6473 - 12s/epoch - 39ms/step\n","Epoch 92/100\n","322/322 - 13s - loss: 0.4015 - accuracy: 0.8518 - val_loss: 1.2169 - val_accuracy: 0.6525 - 13s/epoch - 39ms/step\n","Epoch 93/100\n","322/322 - 13s - loss: 0.4004 - accuracy: 0.8514 - val_loss: 1.2258 - val_accuracy: 0.6535 - 13s/epoch - 39ms/step\n","Epoch 94/100\n","322/322 - 13s - loss: 0.3991 - accuracy: 0.8499 - val_loss: 1.1725 - val_accuracy: 0.6431 - 13s/epoch - 39ms/step\n","Epoch 95/100\n","322/322 - 13s - loss: 0.3876 - accuracy: 0.8560 - val_loss: 1.2460 - val_accuracy: 0.6495 - 13s/epoch - 39ms/step\n","Epoch 96/100\n","322/322 - 12s - loss: 0.3916 - accuracy: 0.8556 - val_loss: 1.2377 - val_accuracy: 0.6492 - 12s/epoch - 39ms/step\n","Epoch 97/100\n","322/322 - 13s - loss: 0.3915 - accuracy: 0.8556 - val_loss: 1.2226 - val_accuracy: 0.6512 - 13s/epoch - 39ms/step\n","Epoch 98/100\n","322/322 - 13s - loss: 0.3848 - accuracy: 0.8576 - val_loss: 1.2507 - val_accuracy: 0.6463 - 13s/epoch - 39ms/step\n","Epoch 99/100\n","322/322 - 12s - loss: 0.3890 - accuracy: 0.8561 - val_loss: 1.1969 - val_accuracy: 0.6418 - 12s/epoch - 39ms/step\n","Epoch 100/100\n","322/322 - 12s - loss: 0.3784 - accuracy: 0.8595 - val_loss: 1.2338 - val_accuracy: 0.6468 - 12s/epoch - 39ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9_A4quFpFJuX","executionInfo":{"status":"ok","timestamp":1685021638222,"user_tz":-180,"elapsed":34,"user":{"displayName":"MUHAMMED UHUDHAN ATES","userId":"03802844268053568357"}}},"execution_count":10,"outputs":[]}]}